"""
Compare hashes from TSV files as generated by hash-sequences
"""

import os
import sys
import glob
import argparse
import typing as t


ProfData = dict[str, str | None]


def run(
        mode: str,
        query: t.TextIO | None,
        fromfile: str | None,
        fromglob: str | None,
        validate: bool,
        header: bool,
        out: t.TextIO,
):
    if not (fromfile or fromglob):
        raise RuntimeError("Must specify at least one of --from-file or --from-glob")
    compare_func = modes[mode]
    # Gather 'other' files
    files = []
    if fromfile:
        with open(fromfile, 'r') as fh:
            for line in fh:
                files.append(line.strip())
    if fromglob:
        files.extend([p for p in glob.glob(fromglob) if p not in files])
    if query and query.name in files:
        files.remove(query.name)  # Remove query in advance
    basenames = set(_get_basename(path) for path in files)
    if len(basenames) != len(files):
        raise RuntimeError("Can't use multiple files with same basename (name when ignoring directory and extension)")
    profiles = [Profile.from_filepath(path=path, validate=validate) for path in files]
    # Add query, if given
    if query:
        query_path = query.name  # Note: should be '<stdin>' if from STDIN
        query_basename = _get_basename(query_path)
        if query_basename in basenames:
            raise RuntimeError("Can't use multiple files with same basename (name when ignoring directory and extension)")
        profiles.append(Profile.from_io(fh=query, validate=validate))
    # Validate input
    if validate:
        check_algo(profiles=profiles)
    # Run and output comparison
    matrix = compare_func(profiles)
    write_output(fh=out, profiles=profiles, matrix=matrix, header=header)


class Profile:

    def __init__(self, name: str, data: ProfData):
        self.name = name
        self.data = data

    @classmethod
    def from_io(cls, fh: t.TextIO, validate: bool) -> 'Profile':
        data = cls.parse_hashes_tsv(fh=fh, validate=validate)
        name = _get_basename(fh.name)
        return cls(name=name, data=data)

    @classmethod
    def from_filepath(cls, path: str, validate: bool) -> 'Profile':
        with open(path, 'r') as fh:
            data = cls.parse_hashes_tsv(fh=fh, validate=validate)
        name = _get_basename(path)
        return cls(name=name, data=data)

    @staticmethod
    def parse_hashes_tsv(fh: t.TextIO, validate: bool) -> ProfData:
        prof: ProfData = dict()
        for idx, line in enumerate(fh):
            k, v, *r = line.strip('\n').split('\t')
            if validate and r:
                raise RuntimeError(f"Too many fields in '{fh.name}', line {idx}: {line}")
            prof[k] = v or None
        return prof


def check_identifiers(profiles: list['Profile']):
    profs_iter = iter(profiles)
    identifiers = set(next(profs_iter).data.keys())
    if len(identifiers) == 0:
        raise RuntimeError("One or more files have no data")
    for other in profs_iter:
        if other.data.keys() != identifiers:
            raise RuntimeError("Not all files have the same identifiers")


def check_algo(profiles: list['Profile']):
    profs_iter = iter(profiles)
    algos = set(_get_algo(v=v) for v in next(profs_iter).data.values() if v)
    if len(algos) > 1:
        raise RuntimeError("Files were generated with a mixture of hashing algorithms")
    algo = algos.pop()
    for other in profs_iter:
        if any(_get_algo(v=v) != algo for v in other.data.values()):
            raise RuntimeError("Files were generated with different hashing algorithms")


def _get_algo(v: str) -> str | None:
    if ':' not in v:
        return None
    else:
        return v.split(':', maxsplit=1)[0]


def _get_basename(v: str) -> str:
    return os.path.splitext(os.path.basename(v))[0]


def compare_all(profiles: list['Profile']) -> list[list[float]]:
    matrix = [[1.0, ] * len(profiles)] * len(profiles)
    for start in range(len(profiles)):
        first, others = profiles[start], profiles[start:]
        for counter, other in enumerate(others):
            score = compare(first=first, second=other)
            matrix[start][start+counter] = score
            matrix[start+counter][start] = score
    return matrix


def compare_single(profiles: list['Profile']) -> list[float]:
    first = profiles[0]
    return [compare(first=first, second=other) for other in profiles]


def compare(first: 'Profile', second: 'Profile') -> float:
    if first == second:
        return 1.0
    # Each comparison only considers the known data for both.
    # Missing identifiers are considered to be the value 'missing' => different from 'present'.
    # If both would be missing an identifier a third may have, this is ignored;
    # it would (unjustly IMO) increase the similarity between the two.
    identifiers = first.data.keys() | second.data.keys()
    total = len(identifiers)
    matches = 0
    for identifier in identifiers:
        v1 = first.data.get(identifier, None)
        v2 = second.data.get(identifier, None)
        if None in (v1, v2):
            continue
        if v1 == v2:
            matches += 1
    return matches / total


def write_output(fh: t.TextIO, profiles: list['Profile'], matrix: list[list[float]], header: bool):
    names = [p.name for p in profiles]
    if header:
        fh.write('\t' + '\t'.join(names) + '\n')
    for name, row in zip(names, matrix, strict=False):
        full_row = [name, ] + [str(v) for v in row]
        fh.write('\t'.join(full_row) + '\n')


modes: dict[str, t.Callable[[list['Profile']], list[list[float]]]] = {
    'single': lambda profs: [compare_single(profiles=profs), ],
    'all': compare_all,
}


# -- Run as Script --

def get_argparser():
    parser = argparse.ArgumentParser(
        prog="compare-hashes",
        description="Compare hashes from TSV files as generated by hash-sequences.",
        epilog="Copyright (C) 2022 Jan Deneweth"
    )
    add_argparser_args(parser=parser)
    return parser


def add_argparser_args(parser: argparse.ArgumentParser):
    parser.add_argument('--mode', '-m', type=str, default='single', choices=['single', 'all'], help="Comparison output mode. first: first vs others. all: all-vs-all.")
    parser.add_argument('--query', '-q', type=argparse.FileType('r'), help="The query hashes TSV files, required for mode 'single', use '-' for STDIN")
    parser.add_argument('--from-glob', '-g', type=str, help="Glob pattern to find other files, e.g. \"dir/**/*.tsv\". Ignores the query file if included.")
    parser.add_argument('--from-file', '-g', type=str, help="File with filepaths of other files. Ignores the query file if included.")
    parser.add_argument('--validate', action=argparse.BooleanOptionalAction, default=True, help="Raise errors when constrains fail on format or algorithm")
    parser.add_argument('--header', action=argparse.BooleanOptionalAction, default=True, help="Add a header line with basenames to the output file")
    parser.add_argument('--out', '-o', type=argparse.FileType('w'), default=sys.stdout, help="The output destination, defaults to STDOUT")


def main_ns(ns: argparse.Namespace):
    run(
        mode=ns.mode,
        query=ns.query,
        fromfile=ns.from_file,
        fromglob=ns.from_glob,
        validate=ns.validate,
        header=ns.header,
        out=ns.out,
    )


def main(args: list[str] | None = None):
    parser = get_argparser()
    ns = parser.parse_args(args=args)
    main_ns(ns=ns)


if __name__ == '__main__':
    main()


#
#
# END OF FILE
